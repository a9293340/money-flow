/**
 * OpenAI API å®¢æˆ¶ç«¯æœå‹™
 *
 * æä¾›ï¼š
 * - OpenAI API èª¿ç”¨å°è£
 * - éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶
 * - Token ä½¿ç”¨é‡çµ±è¨ˆ
 * - é€Ÿç‡é™åˆ¶è™•ç†
 */

import type {
  OpenAIConfig,
  AIAnalysisResponse,
} from '~/types/ai'

/**
 * OpenAI èŠå¤©å®Œæˆ API è«‹æ±‚æ ¼å¼
 */
interface ChatCompletionRequest {
  model: string
  messages: Array<{
    role: 'system' | 'user' | 'assistant'
    content: string
  }>
  max_tokens?: number
  temperature?: number
  top_p?: number
  frequency_penalty?: number
  presence_penalty?: number
}

/**
 * OpenAI èŠå¤©å®Œæˆ API å›æ‡‰æ ¼å¼
 */
interface ChatCompletionResponse {
  id: string
  object: string
  created: number
  model: string
  choices: Array<{
    index: number
    message: {
      role: string
      content: string
    }
    finish_reason: string
  }>
  usage: {
    prompt_tokens: number
    completion_tokens: number
    total_tokens: number
  }
}

/**
 * OpenAI å®¢æˆ¶ç«¯é¡åˆ¥
 */
export class OpenAIClient {
  private config: OpenAIConfig
  private baseURL = 'https://api.openai.com/v1'

  constructor(config: OpenAIConfig) {
    this.config = config
    this.validateConfig()
  }

  /**
   * é©—è­‰ API é…ç½®
   */
  private validateConfig(): void {
    if (!this.config.apiKey) {
      throw new Error('OpenAI API Key æœªè¨­å®š')
    }

    if (!this.config.apiKey.startsWith('sk-')) {
      throw new Error('OpenAI API Key æ ¼å¼éŒ¯èª¤')
    }
  }

  /**
   * ç™¼é€èŠå¤©å®Œæˆè«‹æ±‚
   */
  private async sendChatCompletion(
    messages: ChatCompletionRequest['messages'],
    options: Partial<Pick<ChatCompletionRequest, 'max_tokens' | 'temperature'>> = {},
  ): Promise<ChatCompletionResponse> {
    const requestBody: ChatCompletionRequest = {
      model: this.config.model,
      messages,
      max_tokens: options.max_tokens || this.config.maxTokens,
      temperature: options.temperature || this.config.temperature,
    }

    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), this.config.timeout)

    try {
      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.config.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
        signal: controller.signal,
      })

      clearTimeout(timeoutId)

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(
          `OpenAI API èª¿ç”¨å¤±æ•— (${response.status}): ${
            errorData.error?.message || 'æœªçŸ¥éŒ¯èª¤'
          }`,
        )
      }

      return await response.json()
    }
    catch (error) {
      clearTimeout(timeoutId)

      if ((error as Error).name === 'AbortError') {
        throw new Error(`OpenAI API è«‹æ±‚è¶…æ™‚ (${this.config.timeout}ms)`)
      }

      throw error
    }
  }

  /**
   * åŸ·è¡Œè²¡å‹™å¥åº·åˆ†æ
   */
  async analyzeFinancialHealth(
    systemPrompt: string,
    userPrompt: string,
    options?: { maxTokens?: number, temperature?: number },
  ): Promise<AIAnalysisResponse> {
    try {
      const messages = [
        { role: 'system' as const, content: systemPrompt },
        { role: 'user' as const, content: userPrompt },
      ]

      const response = await this.sendChatCompletion(messages, options)

      const analysis = response.choices[0]?.message?.content

      if (!analysis) {
        throw new Error('OpenAI å›æ‡‰å…§å®¹ç‚ºç©º')
      }

      // å˜—è©¦è§£æ JSON æ ¼å¼çš„å›æ‡‰ï¼ˆå¦‚æœæ˜¯çµæ§‹åŒ–è³‡æ–™ï¼‰
      let parsedData: any = analysis
      try {
        if (analysis.trim().startsWith('{')) {
          parsedData = JSON.parse(analysis)
        }
      }
      catch {
        // å¦‚æœä¸æ˜¯ JSONï¼Œä¿æŒåŸå§‹æ–‡å­—
      }

      return {
        success: true,
        data: {
          analysis: typeof parsedData === 'string' ? parsedData : parsedData.analysis || analysis,
          recommendations: parsedData.recommendations || [],
          score: parsedData.score,
          grade: parsedData.grade,
          metrics: parsedData.metrics,
          timestamp: new Date().toISOString(),
        },
        usage: {
          promptTokens: response.usage.prompt_tokens,
          completionTokens: response.usage.completion_tokens,
          totalTokens: response.usage.total_tokens,
          estimatedCost: this.calculateCost(response.usage.total_tokens),
        },
      }
    }
    catch (error) {
      console.error('OpenAI åˆ†æå¤±æ•—:', error)

      return {
        success: false,
        error: {
          code: 'OPENAI_ERROR',
          message: error instanceof Error ? error.message : 'æœªçŸ¥éŒ¯èª¤',
          details: error,
        },
      }
    }
  }

  /**
   * ç”Ÿæˆé ç®—å»ºè­°
   */
  async generateBudgetRecommendation(prompt: {
    systemPrompt: string
    userPrompt: string
  }): Promise<any> {
    try {
      console.log('ğŸ¯ é–‹å§‹ç”Ÿæˆé ç®—å»ºè­°')

      const response = await this.sendChatCompletion([
        {
          role: 'system',
          content: prompt.systemPrompt,
        },
        {
          role: 'user',
          content: prompt.userPrompt,
        },
      ], {
        max_tokens: 1500,
        temperature: 0.7,
      })

      const content = response.choices[0]?.message?.content?.trim()
      if (!content) {
        throw new Error('OpenAI é ç®—å»ºè­°å›æ‡‰å…§å®¹ç‚ºç©º')
      }

      // å˜—è©¦è§£æ JSON å›æ‡‰
      try {
        const jsonMatch = content.match(/\{[\s\S]*\}/)
        if (jsonMatch) {
          const parsed = JSON.parse(jsonMatch[0])
          console.log('âœ… æˆåŠŸè§£æé ç®—å»ºè­° JSON')
          return parsed
        }
      }
      catch (parseError) {
        console.warn('âš ï¸ JSON è§£æå¤±æ•—ï¼Œä½¿ç”¨æ–‡å­—å›æ‡‰:', parseError)
      }

      // å¦‚æœ JSON è§£æå¤±æ•—ï¼Œè¿”å›çµæ§‹åŒ–æ ¼å¼
      return {
        recommendedBudget: {
          totalBudget: 0,
          categories: [],
        },
        recommendations: [content],
        insights: [],
        improvements: [],
        riskWarnings: [],
        nextSteps: [],
        confidence: 0.7,
        methodology: 'åŸºæ–¼ AI æ–‡å­—åˆ†æ',
      }
    }
    catch (error) {
      console.error('ğŸ¯ é ç®—å»ºè­°ç”Ÿæˆå¤±æ•—:', error)
      throw new Error(`é ç®—å»ºè­°ç”Ÿæˆå¤±æ•—: ${error instanceof Error ? error.message : 'æœªçŸ¥éŒ¯èª¤'}`)
    }
  }

  /**
   * ç”Ÿæˆè¶¨å‹¢é æ¸¬
   */
  async generateTrendPrediction(prompt: {
    systemPrompt: string
    userPrompt: string
  }): Promise<any> {
    try {
      console.log('ğŸ“ˆ é–‹å§‹ç”Ÿæˆè¶¨å‹¢é æ¸¬')

      const response = await this.sendChatCompletion([
        {
          role: 'system',
          content: prompt.systemPrompt,
        },
        {
          role: 'user',
          content: prompt.userPrompt,
        },
      ], {
        max_tokens: 1200,
        temperature: 0.6,
      })

      const content = response.choices[0]?.message?.content?.trim()
      if (!content) {
        throw new Error('OpenAI è¶¨å‹¢é æ¸¬å›æ‡‰å…§å®¹ç‚ºç©º')
      }

      // å˜—è©¦è§£æ JSON å›æ‡‰
      try {
        const jsonMatch = content.match(/\{[\s\S]*\}/)
        if (jsonMatch) {
          const parsed = JSON.parse(jsonMatch[0])
          console.log('âœ… æˆåŠŸè§£æè¶¨å‹¢é æ¸¬ JSON')
          return parsed
        }
      }
      catch (parseError) {
        console.warn('âš ï¸ è¶¨å‹¢é æ¸¬ JSON è§£æå¤±æ•—ï¼Œä½¿ç”¨æ–‡å­—å›æ‡‰:', parseError)
      }

      // å¦‚æœ JSON è§£æå¤±æ•—ï¼Œè¿”å›çµæ§‹åŒ–æ ¼å¼
      return {
        predictions: {
          income: { predicted: 0, confidence: 0.5, trend: 'æŒå¹³' },
          expenses: { predicted: 0, confidence: 0.5, trend: 'æŒå¹³' },
          savings: { predicted: 0, confidence: 0.5, trend: 'æŒå¹³' },
        },
        trends: [],
        opportunities: [content],
        risks: [],
        recommendations: [],
        confidence: 0.6,
        methodology: 'åŸºæ–¼ AI æ–‡å­—åˆ†æ',
      }
    }
    catch (error) {
      console.error('ğŸ“ˆ è¶¨å‹¢é æ¸¬ç”Ÿæˆå¤±æ•—:', error)
      throw new Error(`è¶¨å‹¢é æ¸¬ç”Ÿæˆå¤±æ•—: ${error instanceof Error ? error.message : 'æœªçŸ¥éŒ¯èª¤'}`)
    }
  }

  /**
   * è¨ˆç®— API ä½¿ç”¨æˆæœ¬
   */
  private calculateCost(totalTokens: number): number {
    // GPT-3.5-turbo å®šåƒ¹: $0.002 / 1K tokens
    const costPer1KTokens = 0.002
    return (totalTokens / 1000) * costPer1KTokens
  }

  /**
   * æ¸¬è©¦ API é€£æ¥
   */
  async testConnection(): Promise<{
    success: boolean
    message: string
    usage?: ChatCompletionResponse['usage']
  }> {
    try {
      const response = await this.sendChatCompletion([
        {
          role: 'system',
          content: 'ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è²¡å‹™é¡§å•åŠ©æ‰‹ã€‚',
        },
        {
          role: 'user',
          content: 'è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹è²¡å‹™å¥åº·çš„é‡è¦æ€§ã€‚',
        },
      ], { max_tokens: 50 })

      return {
        success: true,
        message: 'OpenAI API é€£æ¥æ­£å¸¸',
        usage: response.usage,
      }
    }
    catch (error) {
      return {
        success: false,
        message: error instanceof Error ? error.message : 'é€£æ¥æ¸¬è©¦å¤±æ•—',
      }
    }
  }

  /**
   * æ›´æ–° API é…ç½®
   */
  updateConfig(newConfig: Partial<OpenAIConfig>): void {
    this.config = { ...this.config, ...newConfig }
    this.validateConfig()
  }

  /**
   * å–å¾—ç›®å‰é…ç½®
   */
  getConfig(): Readonly<OpenAIConfig> {
    return { ...this.config }
  }
}

/**
 * å»ºç«‹ OpenAI å®¢æˆ¶ç«¯å¯¦ä¾‹
 */
export function createOpenAIClient(config?: Partial<OpenAIConfig>): OpenAIClient {
  const defaultConfig: OpenAIConfig = {
    apiKey: process.env.OPEN_AI_KEY || '',
    model: 'gpt-3.5-turbo',
    maxTokens: 1000,
    temperature: 0.7,
    timeout: 30000, // 30 ç§’è¶…æ™‚
  }

  const finalConfig = { ...defaultConfig, ...config }

  return new OpenAIClient(finalConfig)
}

/**
 * å–®ä¾‹ OpenAI å®¢æˆ¶ç«¯
 */
let globalClient: OpenAIClient | null = null

/**
 * å–å¾—æˆ–å»ºç«‹å…¨åŸŸ OpenAI å®¢æˆ¶ç«¯
 */
export function useOpenAIClient(): OpenAIClient {
  if (!globalClient) {
    globalClient = createOpenAIClient()
  }
  return globalClient
}
